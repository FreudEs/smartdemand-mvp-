# parallel_processor.py
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error
from concurrent.futures import ProcessPoolExecutor, as_completed
import traceback

# --- ê¸°ì¡´ ëª¨ë“ˆ ---
from model_trainer import train_prophet_model, train_xgboost_model, predict_xgboost_future
from feature_engineer import create_xgboost_features
from anomaly_analyzer import SmartDemandPreprocessor

# --- [ì‹ ê·œ] ê³ ê¸‰ ê¸°ëŠ¥ ëª¨ë“ˆ ì„í¬íŠ¸ ---
from external_factor_detector import ExternalFactorDetector
from advanced_models import LSTMPredictor, LightGBMPredictor, VolatilityAwareEnsemble

def process_product(args):
    """
    [ìˆ˜ì •] ë‹¨ì¼ í’ˆëª©ì— ëŒ€í•œ ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸.
    ì™¸ë¶€ ìš”ì¸ íƒì§€, ì´ìƒ í˜„ìƒ ë¶„ì„, 4ê°œ ëª¨ë¸ í•™ìŠµ ë° ë™ì  ì•™ìƒë¸”ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    product_name, df_product_orig = args
    print(f"ğŸ”§ {product_name} ì²˜ë¦¬ ì‹œì‘...")
    
    try:
        # --- 1. ì™¸ë¶€ ìš”ì¸ ìë™ íƒì§€ ë° ë³€ë™ì„± ë¶„ì„ ---
        factor_detector = ExternalFactorDetector()
        df_enhanced = factor_detector.detect_and_create_factors(df_product_orig, product_name)
        volatility_info = factor_detector.detected_factors[product_name]['volatility']
        print(f"  âš¡ï¸ {product_name}: ë³€ë™ì„±({volatility_info['level']}) ë¶„ì„ ë° ì™¸ë¶€ ìš”ì¸ í”¼ì²˜ ìƒì„± ì™„ë£Œ.")

        # --- 2. ì´ìƒ í˜„ìƒ ì›ì¸ ë¶„ì„ ---
        anomaly_preprocessor = SmartDemandPreprocessor()
        df_processed, anomaly_log = anomaly_preprocessor.process(df_enhanced)
        if not anomaly_log.empty:
            print(f"  ğŸ•µï¸â€â™‚ï¸ {product_name}: {len(anomaly_log)}ê°œì˜ ì´ìƒ í˜„ìƒ ê°ì§€ ë° ì›ì¸ ë¶„ì„ ì™„ë£Œ.")
        
        # --- 3. ê¸°ë³¸ ëª¨ë¸ í•™ìŠµ (Prophet, XGBoost) ---
        features, target = create_xgboost_features(df_processed, product_name)
        prophet_model, prophet_fc, prophet_test_pred, prophet_perf = train_prophet_model(df_processed, product_name)
        xgb_model, xgb_test_pred, xgb_perf = train_xgboost_model(features, target)

        # --- 4. ê³ ê¸‰ ëª¨ë¸ í•™ìŠµ (LSTM, LightGBM) ---
        lstm_model = LSTMPredictor()
        lstm_result = lstm_model.train(df_processed, product_name)
        
        lgbm_model = LightGBMPredictor()
        lgbm_result = lgbm_model.train(features, target)

        # --- 5. ë™ì  ì•™ìƒë¸” ---
        all_performances = {
            'prophet': prophet_perf.get('Accuracy(%)', 0),
            'xgboost': xgb_perf.get('Accuracy(%)', 0),
            'lstm': lstm_result.get('performance', {}).get('Accuracy(%)', 0),
            'lightgbm': lgbm_result.get('performance', {}).get('Accuracy(%)', 0),
        }
        
        # ì•™ìƒë¸”ì— ì‚¬ìš©í•  ëª¨ë“  ëª¨ë¸ì˜ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ê°’ ìˆ˜ì§‘
        all_test_preds = {
            'prophet': prophet_test_pred if prophet_test_pred is not None else np.array([]),
            'xgboost': xgb_test_pred if xgb_test_pred is not None else np.array([]),
            'lstm': lstm_result.get('predictions', np.array([])),
            'lightgbm': lgbm_result.get('predictions', np.array([]))
        }

        # ì˜ˆì¸¡ê°’ì´ ìˆëŠ” ëª¨ë¸ë§Œ í•„í„°ë§í•˜ê³  ê¸¸ì´ë¥¼ í†µì¼
        valid_preds = {name: pred for name, pred in all_test_preds.items() if len(pred) > 0}
        
        if not valid_preds:
            raise ValueError(f"{product_name}: ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            
        min_len = min(len(pred) for pred in valid_preds.values())
        
        # ê¸¸ì´ê°€ í†µì¼ëœ ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ë¥¼ ìµœì¢…ì ìœ¼ë¡œ ìƒì„±
        all_predictions = {
            name: pred[-min_len:] for name, pred in valid_preds.items()
        }

        # all_predictionsì— í¬í•¨ëœ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ë§Œìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ë‹¤ì‹œ ê³„ì‚°
        performance_for_ensemble = {
            model_name: perf
            for model_name, perf in all_performances.items()
            if model_name in all_predictions
        }

        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì— ëŒ€í•œ ì•™ìƒë¸” ì˜ˆì¸¡ ë° ì„±ëŠ¥ í‰ê°€
        y_true_test = target.iloc[-min_len:].values
        ensemble = VolatilityAwareEnsemble()
        
        ensemble_test_pred = ensemble.ensemble_predict(
            all_predictions,
            volatility_info['cv'],
            performance_for_ensemble
        )
        
        ens_mae = mean_absolute_error(y_true_test, ensemble_test_pred)
        ens_mape = np.mean(np.abs((y_true_test - ensemble_test_pred) / np.maximum(y_true_test, 1))) * 100
        ensemble_perf = {'Accuracy(%)': 100 - ens_mape, 'MAE': ens_mae, 'weights': ensemble.weights}
        
        print(f"  âœ… {product_name} ë™ì  ì•™ìƒë¸” ì •í™•ë„: {ensemble_perf['Accuracy(%)']:.1f}%")

        # ë¯¸ë˜ ì˜ˆì¸¡ (ê°€ì¥ ì„±ëŠ¥ ì¢‹ì€ ë‹¨ì¼ ëª¨ë¸ ë˜ëŠ” ì•™ìƒë¸” ì˜ˆì¸¡)
        xgb_future_pred_df = predict_xgboost_future(df_processed, product_name, xgb_model, 7)
        prophet_future_pred = prophet_fc.tail(7) if prophet_fc is not None else None
        
        ensemble_forecast = None
        if prophet_future_pred is not None and not xgb_future_pred_df.empty:
            prophet_weight = ensemble.weights.get('prophet', 0.5)
            xgb_weight = ensemble.weights.get('xgboost', 0.5)
            total_w = prophet_weight + xgb_weight
            prophet_weight /= total_w
            xgb_weight /= total_w

            prophet_future_pred['ds'] = pd.to_datetime(prophet_future_pred['ds']).dt.normalize()
            xgb_future_pred_df['ë‚ ì§œ'] = pd.to_datetime(xgb_future_pred_df['ë‚ ì§œ']).dt.normalize()
            prophet_future_pred = prophet_future_pred[['ds', 'yhat']].set_index('ds')
            xgb_future_pred = xgb_future_pred_df[['ë‚ ì§œ', 'íŒë§¤ëŸ‰']].set_index('ë‚ ì§œ').rename(columns={'íŒë§¤ëŸ‰': 'yhat'})
            merged_preds = prophet_future_pred.join(xgb_future_pred, lsuffix='_prophet', rsuffix='_xgb', how='outer').fillna(0)
            merged_preds['ensemble_yhat'] = (merged_preds['yhat_prophet'] * prophet_weight) + (merged_preds['yhat_xgb'] * xgb_weight)
            ensemble_forecast = merged_preds[['ensemble_yhat']].reset_index().rename(columns={'index':'ë‚ ì§œ'})


        print(f"  âœ… {product_name} ì²˜ë¦¬ ì™„ë£Œ!")
        
        return product_name, {
            'prophet_performance': prophet_perf, 
            'xgboost_performance': xgb_perf,
            'lstm_performance': lstm_result.get('performance', {}),
            'lightgbm_performance': lgbm_result.get('performance', {}),
            'ensemble_performance': ensemble_perf, 
            'ensemble_forecast': ensemble_forecast,
            'anomaly_log': anomaly_log
        }
    
    except Exception as e:
        print(f"  âŒ {product_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        traceback.print_exc()
        return product_name, {}


def run_parallel_processing(_df):
    """
    ëª¨ë“  í’ˆëª©ì— ëŒ€í•œ ëª¨ë¸ í›ˆë ¨ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ê³ , ì´ìƒ í˜„ìƒ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    """
    models_data = {}
    all_anomaly_logs = []
    
    tasks = [(name, group) for name, group in _df.groupby('í’ˆëª©ëª…')]
    
    print(f"ğŸš€ ì´ {len(tasks)}ê°œ í’ˆëª©ì— ëŒ€í•œ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    # ë³‘ë ¬ ì²˜ë¦¬ ( concurrent.futures ì‚¬ìš© )
    # with ProcessPoolExecutor() as executor:
    #     futures = [executor.submit(process_product, task) for task in tasks]
    #     for future in as_completed(futures):
    #         name, data = future.result()
    #         if data:
    #             models_data[name] = data
    #             if 'anomaly_log' in data and not data['anomaly_log'].empty:
    #                 all_anomaly_logs.append(data['anomaly_log'])
    
    # ìˆœì°¨ ì²˜ë¦¬ (ë””ë²„ê¹…ìš©)
    for task in tasks:
        name, data = process_product(task)
        if data:
            models_data[name] = data
            if 'anomaly_log' in data and data['anomaly_log'] is not None and not data['anomaly_log'].empty:
                all_anomaly_logs.append(data['anomaly_log'])

    if all_anomaly_logs:
        models_data['total_anomaly_log'] = pd.concat(all_anomaly_logs, ignore_index=True)
    else:
        models_data['total_anomaly_log'] = pd.DataFrame()
    
    print(f"\nâœ… ëª¨ë“  í’ˆëª© ì²˜ë¦¬ ì™„ë£Œ! ì„±ê³µ: {len([v for n,v in models_data.items() if n != 'total_anomaly_log' and isinstance(v, dict) and v.get('ensemble_forecast') is not None])}ê°œ")
                
    return models_data
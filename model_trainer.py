# model_trainer.py (ìµœì¢… ìˆ˜ì • ë²„ì „)
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from prophet import Prophet
import xgboost as xgb
from sklearn.metrics import mean_absolute_error
from feature_engineer import create_date_features, create_xgboost_features
from optimizer import optimize_xgboost

MIN_DATA_DAYS = 30

def train_prophet_model(df, product_name):
    """
    Prophet ëª¨ë¸ì„ í›ˆë ¨í•˜ê³  ì˜ˆì¸¡ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
    """
    # í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
    product_df_full = df[df['í’ˆëª©ëª…'] == product_name].copy()
    prophet_data = product_df_full[['ë‚ ì§œ', 'íŒë§¤ëŸ‰']].rename(columns={'ë‚ ì§œ': 'ds', 'íŒë§¤ëŸ‰': 'y'})
    
    # ë°ì´í„° ê²€ì¦
    if len(prophet_data) < MIN_DATA_DAYS:
        print(f"  âš ï¸ {product_name}: ë°ì´í„° ë¶€ì¡± ({len(prophet_data)}ì¼ < {MIN_DATA_DAYS}ì¼)")
        return None, None, None, {'Accuracy(%)': -1, 'MAE': -1}
    
    # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
    test_days = min(30, int(len(prophet_data) * 0.2))
    train_data = prophet_data.iloc[:-test_days]
    test_data = prophet_data.iloc[-test_days:]
    
    try:
        # Prophet ëª¨ë¸ ìƒì„±
        model = Prophet(
            daily_seasonality=True,
            weekly_seasonality=True,
            yearly_seasonality=False,
            seasonality_mode='additive',
            changepoint_prior_scale=0.1,
            interval_width=0.95
        )
        
        # íœ´ì¼/ì´ë²¤íŠ¸ ì²˜ë¦¬ (ìˆëŠ” ê²½ìš°)
        if 'ì´ë²¤íŠ¸' in product_df_full.columns:
            holidays_df = product_df_full[product_df_full['ì´ë²¤íŠ¸'].notna()][['ë‚ ì§œ', 'ì´ë²¤íŠ¸']]
            if not holidays_df.empty:
                holidays_df = holidays_df.rename(columns={'ë‚ ì§œ': 'ds', 'ì´ë²¤íŠ¸': 'holiday'})
                model = Prophet(
                    holidays=holidays_df,
                    daily_seasonality=True,
                    weekly_seasonality=True,
                    yearly_seasonality=False,
                    seasonality_mode='additive',
                    changepoint_prior_scale=0.1
                )
        
        # ëª¨ë¸ í•™ìŠµ
        model.fit(train_data)
        
        # í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
        future = model.make_future_dataframe(periods=test_days, freq='D')
        forecast = model.predict(future)
        
        # ì„±ëŠ¥ í‰ê°€
        y_true = test_data['y'].values
        y_pred_test = forecast.tail(test_days)['yhat'].values
        y_pred_test = np.maximum(y_pred_test, 0)  # ìŒìˆ˜ ì œê±°
        
        mae = mean_absolute_error(y_true, y_pred_test)
        mape = np.mean(np.abs((y_true - y_pred_test) / np.maximum(y_true, 1))) * 100
        performance = {'Accuracy(%)': 100 - mape, 'MAE': mae}
        
        # ë¯¸ë˜ 7ì¼ ì˜ˆì¸¡
        final_future = model.make_future_dataframe(periods=7, freq='D')
        final_forecast = model.predict(final_future)
        final_forecast['yhat'] = np.maximum(final_forecast['yhat'], 0)
        
        print(f"  âœ… {product_name}: Prophet í•™ìŠµ ì™„ë£Œ (ì •í™•ë„: {performance['Accuracy(%)']:.1f}%)")
        
        return model, final_forecast, y_pred_test, performance
        
    except Exception as e:
        print(f"  âŒ {product_name}: Prophet í•™ìŠµ ì‹¤íŒ¨ - {str(e)}")
        return None, None, None, {'Accuracy(%)': -1, 'MAE': -1}


def train_xgboost_model(features, target):
    """
    XGBoost ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
    """
    if len(features) < MIN_DATA_DAYS + 30:
        print(f"  âš ï¸ XGBoost: ë°ì´í„° ë¶€ì¡± ({len(features)}í–‰)")
        return None, None, {'Accuracy(%)': -1, 'MAE': -1}
    
    try:
        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
        test_days = 30
        X_test, y_test = features.iloc[-test_days:], target.iloc[-test_days:]
        X_train, y_train = features.iloc[:-test_days], target.iloc[:-test_days]
        
        # Optuna ìµœì í™”
        print(f"  ğŸ” XGBoost í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘...")
        best_params = optimize_xgboost(X_train, y_train)
        
        # ëª¨ë¸ í•™ìŠµ
        final_model = xgb.XGBRegressor(**best_params, random_state=42)
        final_model.fit(X_train, y_train, verbose=False)
        
        # ì˜ˆì¸¡ ë° í‰ê°€
        y_pred_test = np.maximum(final_model.predict(X_test), 0)
        mae = mean_absolute_error(y_test.values, y_pred_test)
        mape = np.mean(np.abs((y_test.values - y_pred_test) / np.maximum(y_test.values, 1))) * 100
        performance = {'Accuracy(%)': 100 - mape, 'MAE': mae}
        
        print(f"  âœ… XGBoost í•™ìŠµ ì™„ë£Œ (ì •í™•ë„: {performance['Accuracy(%)']:.1f}%)")
        
        return final_model, y_pred_test, performance
        
    except Exception as e:
        print(f"  âŒ XGBoost í•™ìŠµ ì‹¤íŒ¨ - {str(e)}")
        return None, None, {'Accuracy(%)': -1, 'MAE': -1}


def predict_xgboost_future(df, product_name, xgb_model, days_to_predict=7):
    """
    XGBoost ëª¨ë¸ë¡œ ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    íŠ¹ì§• ë¶ˆì¼ì¹˜ ë¬¸ì œë¥¼ í•´ê²°í•œ ë²„ì „
    """
    if xgb_model is None:
        return pd.DataFrame()
    
    try:
        # 1. í•™ìŠµ ì‹œ ì‚¬ìš©ëœ íŠ¹ì§• ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
        try:
            expected_features = xgb_model.get_booster().feature_names
            if expected_features is None:
                # feature_namesê°€ Noneì¸ ê²½ìš° n_features_in_ë¥¼ ì‚¬ìš©
                n_features = xgb_model.n_features_in_
                expected_features = [f'f{i}' for i in range(n_features)]
                print(f"    ê²½ê³ : feature_namesê°€ Noneì…ë‹ˆë‹¤. íŠ¹ì§• ìˆ˜: {n_features}")
            else:
                print(f"    ì˜ˆìƒ íŠ¹ì§• ìˆ˜: {len(expected_features)}")
        except:
            # ì•ˆì „ì¥ì¹˜: ëª¨ë“  íŠ¹ì§• ì‚¬ìš©
            expected_features = None
            print("    ê²½ê³ : íŠ¹ì§• ì´ë¦„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # 2. ê³¼ê±° ë°ì´í„° ì¤€ë¹„
        historical_df = df[df['í’ˆëª©ëª…'] == product_name].copy()
        last_date = historical_df['ë‚ ì§œ'].max()
        future_predictions = []
        
        # 3. ë°˜ë³µì ìœ¼ë¡œ 1ì¼ì”© ì˜ˆì¸¡
        for i in range(days_to_predict):
            next_date = last_date + pd.Timedelta(days=i + 1)
            
             # [í•µì‹¬ ìˆ˜ì •] historical_dfì˜ ë§ˆì§€ë§‰ í–‰ì„ ë³µì‚¬í•˜ì—¬ ëª¨ë“  í”¼ì²˜ ì»¬ëŸ¼ì„ ìœ ì§€
            # ì´ë ‡ê²Œ í•˜ë©´ is_anomaly ë“± ëª¨ë“  ì»¬ëŸ¼ì´ ìë™ìœ¼ë¡œ í¬í•¨ë¨
            next_day_row = historical_df.iloc[-1:].copy()
            next_day_row['ë‚ ì§œ'] = next_date
            next_day_row['íŒë§¤ëŸ‰'] = 0  # ì˜ˆì¸¡ì„ ìœ„í•´ ì„ì‹œë¡œ 0ì„ ì„¤ì •
            
            # ê¸°ì¡´ ë°ì´í„°ì™€ ê²°í•©
            temp_df = pd.concat([historical_df, next_day_row], ignore_index=True)
            
            # ë‚ ì§œ íŠ¹ì§• ìƒì„±
            temp_df = create_date_features(temp_df)
            
            # anomaly ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ë‹¤ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€
            if 'is_anomaly' not in temp_df.columns:
                temp_df['is_anomaly'] = False
            if 'anomaly_type' not in temp_df.columns:
                temp_df['anomaly_type'] = 'ì •ìƒ'
            if 'anomaly_reason' not in temp_df.columns:
                temp_df['anomaly_reason'] = 'ì •ìƒ'
            if 'anomaly_score' not in temp_df.columns:
                temp_df['anomaly_score'] = 0.0
            
            # ë‹¤ë¥¸ ì™¸ë¶€ ë³€ìˆ˜ë“¤ë„ forward fill
            external_vars = ['ì˜ˆì¸¡ìˆ˜ìš”', 'ì¬ê³ ëŸ‰', 'ê¸°ì˜¨', 'ê°•ìˆ˜ëŸ‰', 'ì´ë²¤íŠ¸']
            for var in external_vars:
                if var in temp_df.columns:
                    temp_df[var] = temp_df[var].fillna(method='ffill').fillna(method='bfill')
            
            # íŠ¹ì§• ìƒì„±
            features, _ = create_xgboost_features(temp_df, product_name)
            
            # ë§ˆì§€ë§‰ í–‰(ë¯¸ë˜ ë‚ ì§œ)ì˜ íŠ¹ì§•ë§Œ ì¶”ì¶œ
            last_features = features.tail(1)
            
            # íŠ¹ì§• ìˆœì„œ ë§ì¶”ê¸° (ì¤‘ìš”!)
            if expected_features:
                # í•™ìŠµ ì‹œ ì‚¬ìš©ëœ íŠ¹ì§•ë§Œ ì„ íƒí•˜ê³  ìˆœì„œë„ ë§ì¶¤
                missing_features = set(expected_features) - set(last_features.columns)
                if missing_features:
                    print(f"    ê²½ê³ : ëˆ„ë½ëœ íŠ¹ì§• {missing_features}")
                    # ëˆ„ë½ëœ íŠ¹ì§•ì€ 0ìœ¼ë¡œ ì±„ì›€
                    for feat in missing_features:
                        last_features[feat] = 0
                
                # ìˆœì„œ ë§ì¶”ê¸°
                last_features = last_features[expected_features]
            
            # ì˜ˆì¸¡
            next_pred = max(0, xgb_model.predict(last_features)[0])
            
            # ì˜ˆì¸¡ê°’ì„ historical_dfì— ì¶”ê°€
            new_row = pd.DataFrame({
                'ë‚ ì§œ': [next_date],
                'í’ˆëª©ëª…': [product_name],
                'íŒë§¤ëŸ‰': [next_pred],
                'is_anomaly': [False],  # ë¯¸ë˜ëŠ” ì •ìƒìœ¼ë¡œ ê°€ì •
                'anomaly_type': ['ì •ìƒ'],
                'anomaly_reason': ['ì •ìƒ'],
                'anomaly_score': [0.0]
            })
            
            # ì™¸ë¶€ ë³€ìˆ˜ë„ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
            for var in external_vars:
                if var in historical_df.columns:
                    new_row[var] = historical_df[var].iloc[-1]  # ë§ˆì§€ë§‰ ê°’ ì‚¬ìš©
            
            historical_df = pd.concat([historical_df, new_row], ignore_index=True)
            
            future_predictions.append({'ë‚ ì§œ': next_date, 'íŒë§¤ëŸ‰': next_pred})
        
        print(f"    âœ… XGBoost ë¯¸ë˜ ì˜ˆì¸¡ ì„±ê³µ")
        return pd.DataFrame(future_predictions)
        
    except Exception as e:
        print(f"  âŒ XGBoost ë¯¸ë˜ ì˜ˆì¸¡ ì‹¤íŒ¨ - {str(e)}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()